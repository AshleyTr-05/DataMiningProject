================================================================================
=== HEART DISEASE CLASSIFICATION SYSTEM ===
================================================================================

--- Dataset Information ---
Dataset Name: heart_disease-weka.filters.unsupervised.instance.RemoveDuplicates-weka.filters.unsupervised.attribute.NominalToBinary-Rfirst-last
Number of Instances: 10000
Number of Attributes: 30
Class Attribute: Heart Disease Status
Class Values: No Yes 

================================================================================
=== TRAINING AND EVALUATING CLASSIFIERS ===
================================================================================

????????????????????????????????????????????????????????????????????????????????
? 1. J48 DECISION TREE
????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? ALGORITHM DESCRIPTION                                                       ?
????????????????????????????????????????????????????????????????????????????????
Algorithm: J48 (C4.5 Decision Tree)
Description:
  - Uses information gain to select the best attribute for splitting
  - Builds a tree structure where each node represents a decision
  - Performs pruning to avoid overfitting
  - Handles both continuous and discrete attributes
Advantages:
  - Easy to interpret and visualize
  - Handles non-linear relationships well
  - Requires little data preprocessing

--- Training Classifier ---
Training completed in 936 ms

--- Performing 10-Fold Cross-Validation ---
Evaluation completed in 4648 ms

????????????????????????????????????????????????????????????????????????????????
? CLASSIFICATION RESULTS                                                      ?
????????????????????????????????????????????????????????????????????????????????

=== Overall Performance Metrics ===
Correctly Classified Instances: 7201 (72,0100%)
Incorrectly Classified Instances: 2799 (27,9900%)
Total Number of Instances: 10000

=== Detailed Accuracy Metrics ===
Accuracy: 72,0100%
Kappa Statistic: -0,0040
Mean Absolute Error: 0,3251
Root Mean Squared Error: 0,4961
Relative Absolute Error: 101,5785%
Root Relative Squared Error: 124,0218%

=== Confusion Matrix ===
                 Predicted
              No      Yes
        ???????????????????
Actual No?   6944    1056 ?
      Yes?   1743     257 ?
        ???????????????????

=== Class-Specific Performance ===

Class: No
  Precision (PPV): 0,7994
  Recall (TPR):    0,8680
  F-Measure:       0,8323
  ROC Area:        0,4959
  PRC Area:        0,7989

Class: Yes
  Precision (PPV): 0,1957
  Recall (TPR):    0,1285
  F-Measure:       0,1551
  ROC Area:        0,4959
  PRC Area:        0,1983

=== Weighted Average Metrics ===
Weighted Precision: 0,6786
Weighted Recall:    0,7201
Weighted F-Measure: 0,6968
Weighted ROC Area:  0,4959
Weighted PRC Area:  0,6788

????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? 2. NAIVE BAYES
????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? ALGORITHM DESCRIPTION                                                       ?
????????????????????????????????????????????????????????????????????????????????
Algorithm: Naive Bayes
Description:
  - Based on Bayes' theorem with naive independence assumption
  - Assumes all features are independent given the class
  - Calculates P(Class|Features) for classification
  - Fast and efficient for large datasets
Advantages:
  - Simple and fast training
  - Works well with small training datasets
  - Handles high-dimensional data effectively

--- Training Classifier ---
Training completed in 64 ms

--- Performing 10-Fold Cross-Validation ---
Evaluation completed in 321 ms

????????????????????????????????????????????????????????????????????????????????
? CLASSIFICATION RESULTS                                                      ?
????????????????????????????????????????????????????????????????????????????????

=== Overall Performance Metrics ===
Correctly Classified Instances: 8000 (80,0000%)
Incorrectly Classified Instances: 2000 (20,0000%)
Total Number of Instances: 10000

=== Detailed Accuracy Metrics ===
Accuracy: 80,0000%
Kappa Statistic: 0,0000
Mean Absolute Error: 0,3204
Root Mean Squared Error: 0,4008
Relative Absolute Error: 100,1007%
Root Relative Squared Error: 100,2121%

=== Confusion Matrix ===
                 Predicted
              No      Yes
        ???????????????????
Actual No?   8000       0 ?
      Yes?   2000       0 ?
        ???????????????????

=== Class-Specific Performance ===

Class: No
  Precision (PPV): 0,8000
  Recall (TPR):    1,0000
  F-Measure:       0,8889
  ROC Area:        0,4958
  PRC Area:        0,7995

Class: Yes
  Precision (PPV): NaN
  Recall (TPR):    0,0000
  F-Measure:       NaN
  ROC Area:        0,4958
  PRC Area:        0,1967

=== Weighted Average Metrics ===
Weighted Precision: NaN
Weighted Recall:    0,8000
Weighted F-Measure: NaN
Weighted ROC Area:  0,4958
Weighted PRC Area:  0,6789

????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? 3. SUPPORT VECTOR MACHINE (SVM)
????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? ALGORITHM DESCRIPTION                                                       ?
????????????????????????????????????????????????????????????????????????????????
Algorithm: Support Vector Machine (Sequential Minimal Optimization)
Description:
  - Finds optimal hyperplane to separate classes
  - Maximizes the margin between support vectors
  - Uses kernel trick for non-linear classification
  - SMO is an efficient algorithm for training SVM
Advantages:
  - Effective in high-dimensional spaces
  - Memory efficient (uses support vectors only)
  - Versatile with different kernel functions

--- Training Classifier ---
Training completed in 5817 ms

--- Performing 10-Fold Cross-Validation ---
Evaluation completed in 116037 ms

????????????????????????????????????????????????????????????????????????????????
? CLASSIFICATION RESULTS                                                      ?
????????????????????????????????????????????????????????????????????????????????

=== Overall Performance Metrics ===
Correctly Classified Instances: 8000 (80,0000%)
Incorrectly Classified Instances: 2000 (20,0000%)
Total Number of Instances: 10000

=== Detailed Accuracy Metrics ===
Accuracy: 80,0000%
Kappa Statistic: 0,0000
Mean Absolute Error: 0,2000
Root Mean Squared Error: 0,4472
Relative Absolute Error: 62,4922%
Root Relative Squared Error: 111,8034%

=== Confusion Matrix ===
                 Predicted
              No      Yes
        ???????????????????
Actual No?   8000       0 ?
      Yes?   2000       0 ?
        ???????????????????

=== Class-Specific Performance ===

Class: No
  Precision (PPV): 0,8000
  Recall (TPR):    1,0000
  F-Measure:       0,8889
  ROC Area:        0,5000
  PRC Area:        0,8000

Class: Yes
  Precision (PPV): NaN
  Recall (TPR):    0,0000
  F-Measure:       NaN
  ROC Area:        0,5000
  PRC Area:        0,2000

=== Weighted Average Metrics ===
Weighted Precision: NaN
Weighted Recall:    0,8000
Weighted F-Measure: NaN
Weighted ROC Area:  0,5000
Weighted PRC Area:  0,6800

????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? 4. k-NEAREST NEIGHBORS (k=3)
????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? ALGORITHM DESCRIPTION                                                       ?
????????????????????????????????????????????????????????????????????????????????
Algorithm: k-Nearest Neighbors (k=3)
Description:
  - Instance-based learning algorithm
  - Classifies based on majority vote of k nearest neighbors
  - Uses distance metrics (typically Euclidean)
  - k=3 means considers 3 closest neighbors
Advantages:
  - Simple and intuitive
  - No training phase (lazy learning)
  - Adapts easily as new data is added

--- Training Classifier ---
Training completed in 3 ms

--- Performing 10-Fold Cross-Validation ---
Evaluation completed in 26219 ms

????????????????????????????????????????????????????????????????????????????????
? CLASSIFICATION RESULTS                                                      ?
????????????????????????????????????????????????????????????????????????????????

=== Overall Performance Metrics ===
Correctly Classified Instances: 7388 (73,8800%)
Incorrectly Classified Instances: 2612 (26,1200%)
Total Number of Instances: 10000

=== Detailed Accuracy Metrics ===
Accuracy: 73,8800%
Kappa Statistic: 0,0123
Mean Absolute Error: 0,3180
Root Mean Squared Error: 0,4596
Relative Absolute Error: 99,3564%
Root Relative Squared Error: 114,9103%

=== Confusion Matrix ===
                 Predicted
              No      Yes
        ???????????????????
Actual No?   7157     843 ?
      Yes?   1769     231 ?
        ???????????????????

=== Class-Specific Performance ===

Class: No
  Precision (PPV): 0,8018
  Recall (TPR):    0,8946
  F-Measure:       0,8457
  ROC Area:        0,5096
  PRC Area:        0,8033

Class: Yes
  Precision (PPV): 0,2151
  Recall (TPR):    0,1155
  F-Measure:       0,1503
  ROC Area:        0,5096
  PRC Area:        0,2042

=== Weighted Average Metrics ===
Weighted Precision: 0,6845
Weighted Recall:    0,7388
Weighted F-Measure: 0,7066
Weighted ROC Area:  0,5096
Weighted PRC Area:  0,6834

????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? 5. RANDOM FOREST
????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????
? ALGORITHM DESCRIPTION                                                       ?
????????????????????????????????????????????????????????????????????????????????
Algorithm: Random Forest
Description:
  - Ensemble method using multiple decision trees
  - Each tree is trained on random subset of data
  - Final prediction is majority vote of all trees
  - Uses feature bagging to reduce overfitting
Advantages:
  - High accuracy and robustness
  - Handles large datasets with high dimensionality
  - Provides feature importance rankings

--- Training Classifier ---
Training completed in 12716 ms

--- Performing 10-Fold Cross-Validation ---
Evaluation completed in 56941 ms

????????????????????????????????????????????????????????????????????????????????
? CLASSIFICATION RESULTS                                                      ?
????????????????????????????????????????????????????????????????????????????????

=== Overall Performance Metrics ===
Correctly Classified Instances: 8000 (80,0000%)
Incorrectly Classified Instances: 2000 (20,0000%)
Total Number of Instances: 10000

=== Detailed Accuracy Metrics ===
Accuracy: 80,0000%
Kappa Statistic: 0,0000
Mean Absolute Error: 0,3275
Root Mean Squared Error: 0,4038
Relative Absolute Error: 102,3378%
Root Relative Squared Error: 100,9553%

=== Confusion Matrix ===
                 Predicted
              No      Yes
        ???????????????????
Actual No?   8000       0 ?
      Yes?   2000       0 ?
        ???????????????????

=== Class-Specific Performance ===

Class: No
  Precision (PPV): 0,8000
  Recall (TPR):    1,0000
  F-Measure:       0,8889
  ROC Area:        0,4991
  PRC Area:        0,8026

Class: Yes
  Precision (PPV): NaN
  Recall (TPR):    0,0000
  F-Measure:       NaN
  ROC Area:        0,4991
  PRC Area:        0,1995

=== Weighted Average Metrics ===
Weighted Precision: NaN
Weighted Recall:    0,8000
Weighted F-Measure: NaN
Weighted ROC Area:  0,4991
Weighted PRC Area:  0,6820

????????????????????????????????????????????????????????????????????????????????

================================================================================
ALL CLASSIFIERS COMPLETED SUCCESSFULLY
================================================================================
